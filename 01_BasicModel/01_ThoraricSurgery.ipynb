{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 폐병 환자 수술(Thoraric Surgery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - DEEP LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>293</td>\n",
       "      <td>1</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.88</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.06</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2.21</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1     2     3   4   5   6   7   8   9   10  11  12  13  14  15  16  17\n",
       "0  293   1  3.80  2.80   0   0   0   0   0   0  12   0   0   0   1   0  62   0\n",
       "1    1   2  2.88  2.16   1   0   0   0   1   1  14   0   0   0   1   0  60   0\n",
       "2    8   2  3.19  2.50   1   0   0   0   1   0  11   0   0   1   1   0  66   1\n",
       "3   14   2  3.98  3.06   2   0   0   0   1   1  14   0   0   0   1   0  80   1\n",
       "4   17   2  2.21  1.88   0   0   1   0   0   0  12   0   0   0   1   0  56   0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/ThoraricSurgery.csv',header = None)\r\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>293</td>\n",
       "      <td>1</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.88</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.06</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2.21</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>98</td>\n",
       "      <td>6</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>369</td>\n",
       "      <td>6</td>\n",
       "      <td>3.88</td>\n",
       "      <td>2.72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>406</td>\n",
       "      <td>6</td>\n",
       "      <td>5.36</td>\n",
       "      <td>3.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>4.32</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>447</td>\n",
       "      <td>8</td>\n",
       "      <td>5.20</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1     2     3   4   5   6   7   8   9   10  11  12  13  14  15  16\n",
       "0    293   1  3.80  2.80   0   0   0   0   0   0  12   0   0   0   1   0  62\n",
       "1      1   2  2.88  2.16   1   0   0   0   1   1  14   0   0   0   1   0  60\n",
       "2      8   2  3.19  2.50   1   0   0   0   1   0  11   0   0   1   1   0  66\n",
       "3     14   2  3.98  3.06   2   0   0   0   1   1  14   0   0   0   1   0  80\n",
       "4     17   2  2.21  1.88   0   0   1   0   0   0  12   0   0   0   1   0  56\n",
       "..   ...  ..   ...   ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
       "465   98   6  3.04  2.40   2   0   0   0   1   0  11   0   0   0   1   0  76\n",
       "466  369   6  3.88  2.72   1   0   0   0   1   0  12   0   0   0   1   0  77\n",
       "467  406   6  5.36  3.96   1   0   0   0   1   0  12   0   0   0   0   0  62\n",
       "468   25   8  4.32  3.20   0   0   0   0   0   0  11   0   0   0   0   0  58\n",
       "469  447   8  5.20  4.10   0   0   0   0   0   0  12   0   0   0   0   0  49\n",
       "\n",
       "[470 rows x 17 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      1\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "465    0\n",
       "466    0\n",
       "467    0\n",
       "468    1\n",
       "469    0\n",
       "Name: 17, Length: 470, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((352, 17), (118, 17), (352,), (118,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(  \r\n",
    "    df.iloc[:,:-1].values, df.iloc[:,-1].values\r\n",
    ")\r\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 모델정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\r\n",
    "seed = 2021 # 할때마다 동일한 결과를 내기 위해 seed 값 지정함\r\n",
    "np.random.seed(seed)\r\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 30)                540       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 571\n",
      "Trainable params: 571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\r\n",
    "model.add(Dense(30,input_shape=(17, ), activation ='relu' ))  # input의 행개수와 X_train.shape의 열개수가 같아야함\r\n",
    "model.add(Dense(1, activation= 'sigmoid'))\r\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델 컴파일 = 실행환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\r\n",
    "loss = 'binary_crossentropy', #이진분류의 loss 함수는 binary_crossentropy, 범주형분류는 categorical_crossentropy\r\n",
    "optimizer = 'adam',\r\n",
    "metrics = ['accuracy']\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 모델학습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 6.5240 - accuracy: 0.3096 - val_loss: 2.4290 - val_accuracy: 0.6197\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.3335 - accuracy: 0.6904 - val_loss: 2.0024 - val_accuracy: 0.8028\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.0979 - accuracy: 0.7473 - val_loss: 1.6964 - val_accuracy: 0.7887\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.7924 - accuracy: 0.7900 - val_loss: 1.2649 - val_accuracy: 0.8169\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.2303 - accuracy: 0.7972 - val_loss: 0.7446 - val_accuracy: 0.8028\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7102 - accuracy: 0.7509 - val_loss: 0.5162 - val_accuracy: 0.8310\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.8221 - val_loss: 0.3954 - val_accuracy: 0.8592\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.8292 - val_loss: 0.4106 - val_accuracy: 0.8592\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.8399 - val_loss: 0.3777 - val_accuracy: 0.8732\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.8363 - val_loss: 0.4200 - val_accuracy: 0.8592\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.8363 - val_loss: 0.3825 - val_accuracy: 0.8732\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.8363 - val_loss: 0.3847 - val_accuracy: 0.8732\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.8399 - val_loss: 0.3747 - val_accuracy: 0.8732\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.8363 - val_loss: 0.3841 - val_accuracy: 0.8732\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.8363 - val_loss: 0.3773 - val_accuracy: 0.8732\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.8363 - val_loss: 0.4070 - val_accuracy: 0.8732\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.8363 - val_loss: 0.3841 - val_accuracy: 0.8873\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.8327 - val_loss: 0.4048 - val_accuracy: 0.8732\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.8363 - val_loss: 0.3837 - val_accuracy: 0.8873\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.8363 - val_loss: 0.4157 - val_accuracy: 0.8732\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.8399 - val_loss: 0.3721 - val_accuracy: 0.8873\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.8363 - val_loss: 0.3711 - val_accuracy: 0.8873\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.8363 - val_loss: 0.4314 - val_accuracy: 0.8873\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.8399 - val_loss: 0.3809 - val_accuracy: 0.8732\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.8363 - val_loss: 0.4181 - val_accuracy: 0.8732\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.8363 - val_loss: 0.3671 - val_accuracy: 0.8873\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.8399 - val_loss: 0.3667 - val_accuracy: 0.8873\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.8399 - val_loss: 0.3981 - val_accuracy: 0.8873\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.8363 - val_loss: 0.3604 - val_accuracy: 0.8873\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.8399 - val_loss: 0.3687 - val_accuracy: 0.8873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14dd4035310>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\r\n",
    "    X_train, y_train, \r\n",
    "    validation_split= 0.2, #테스트해보는 셋 지정\r\n",
    "    epochs= 30, #epochs가 너무 크면 과대적합의 위험이 있다.\r\n",
    "    batch_size=30 #한번에 처리할 수 있는 양을 지정\r\n",
    "    )\r\n",
    "    # epoch이 1->30으로 갈수록 시간은 줄어들고, loss는 줄어들고, accuracy는 늘어남 # 이 과정 그래프 시각화 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 정확도 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 748us/step - loss: 0.4572 - accuracy: 0.8220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4571772515773773, 0.8220338821411133]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - MACHINE LEARNING과의 비교 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "scaler = MinMaxScaler()\r\n",
    "X_scaled = scaler.fit_transform(df.iloc[:, :-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((352, 17), (118, 17), (352,), (118,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(  \r\n",
    "   X_scaled,  df.iloc[:,-1].values, \r\n",
    "    stratify = df.iloc[:, -1].values, random_state = 2021\r\n",
    ")\r\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8389830508474576"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\r\n",
    "lr.fit(X_train, y_train)\r\n",
    "pred = lr.predict(X_test)\r\n",
    "accuracy_score(y_test, pred)\r\n",
    "# deep learning (0.8220338821411133) 과 비슷한 결과 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Scale된 데이터로 딥러닝을 수행하면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 30)                540       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 571\n",
      "Trainable params: 571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\r\n",
    "model2.add(Dense(30,input_shape=(17, ), activation ='relu' ))  # input의 행개수와 X_train.shape의 열개수가 같아야함\r\n",
    "model2.add(Dense(1, activation= 'sigmoid'))\r\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(\r\n",
    "    loss = 'binary_crossentropy', optimizer = 'adam',  metrics=['accuracy']\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.9353 - accuracy: 0.1352 - val_loss: 0.8454 - val_accuracy: 0.1972\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8371 - accuracy: 0.1601 - val_loss: 0.7702 - val_accuracy: 0.2394\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7566 - accuracy: 0.2349 - val_loss: 0.7092 - val_accuracy: 0.3380\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6894 - accuracy: 0.5445 - val_loss: 0.6586 - val_accuracy: 0.7606\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6300 - accuracy: 0.8114 - val_loss: 0.6165 - val_accuracy: 0.7887\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5798 - accuracy: 0.8505 - val_loss: 0.5782 - val_accuracy: 0.8028\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5316 - accuracy: 0.8683 - val_loss: 0.5469 - val_accuracy: 0.8028\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4930 - accuracy: 0.8648 - val_loss: 0.5244 - val_accuracy: 0.8028\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.8648 - val_loss: 0.5099 - val_accuracy: 0.8028\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.8648 - val_loss: 0.5013 - val_accuracy: 0.8028\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8648 - val_loss: 0.4982 - val_accuracy: 0.8028\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8648 - val_loss: 0.4981 - val_accuracy: 0.8028\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8648 - val_loss: 0.4982 - val_accuracy: 0.8028\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4090 - accuracy: 0.8648 - val_loss: 0.4999 - val_accuracy: 0.8028\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.8648 - val_loss: 0.5016 - val_accuracy: 0.8028\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8648 - val_loss: 0.5027 - val_accuracy: 0.8028\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.8648 - val_loss: 0.5023 - val_accuracy: 0.8028\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4001 - accuracy: 0.8648 - val_loss: 0.5025 - val_accuracy: 0.8028\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3981 - accuracy: 0.8648 - val_loss: 0.5027 - val_accuracy: 0.8028\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8648 - val_loss: 0.5028 - val_accuracy: 0.8028\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3954 - accuracy: 0.8648 - val_loss: 0.5017 - val_accuracy: 0.8028\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3939 - accuracy: 0.8648 - val_loss: 0.5016 - val_accuracy: 0.8028\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3926 - accuracy: 0.8648 - val_loss: 0.4999 - val_accuracy: 0.8028\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8648 - val_loss: 0.4975 - val_accuracy: 0.8028\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8648 - val_loss: 0.4964 - val_accuracy: 0.8028\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8648 - val_loss: 0.4959 - val_accuracy: 0.8028\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3867 - accuracy: 0.8648 - val_loss: 0.4952 - val_accuracy: 0.8028\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8648 - val_loss: 0.4924 - val_accuracy: 0.8028\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3840 - accuracy: 0.8648 - val_loss: 0.4914 - val_accuracy: 0.8028\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3827 - accuracy: 0.8648 - val_loss: 0.4899 - val_accuracy: 0.8028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14dd4e1e640>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(\r\n",
    "    X_train, y_train, validation_split=0.2,\r\n",
    "    epochs=30, batch_size=30\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/4 [======>.......................] - ETA: 0s - loss: 0.6341 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.4375 - accuracy: 0.8475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4375151991844177, 0.8474576473236084]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test, y_test)\r\n",
    "# scaling하나 안하나 비슷한 결과나옴 "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8c1eae21719a0790335dcb83aad72b63b602cfe5cdb2bda0f60bc11d4f154e4b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}