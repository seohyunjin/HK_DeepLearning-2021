{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PimaIndian 피마 인디언 당뇨병 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2021 # 할때마다 동일한 결과를 내기 위해 seed 값 지정함\r\n",
    "np.random.seed(seed)\r\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1   2   3    4     5      6   7  8\n",
       "0  6  148  72  35    0  33.6  0.627  50  1\n",
       "1  1   85  66  29    0  26.6  0.351  31  0\n",
       "2  8  183  64   0    0  23.3  0.672  32  1\n",
       "3  1   89  66  23   94  28.1  0.167  21  0\n",
       "4  0  137  40  35  168  43.1  2.288  33  1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/pima-indians-diabetes.csv',header = None)\r\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((576, 8), (192, 8), (576,), (192,))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(  \r\n",
    "    df.iloc[:,:-1].values, df.iloc[:,-1].values,\r\n",
    "    stratify = df.iloc[:,-1], random_state = seed\r\n",
    ")\r\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 정의 / 설정 / 학습 / 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### 12/8/1 layer, 200 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\r\n",
    "model.add(Dense(12,input_shape=(8, ), activation ='relu' ) ) # Hidden Layer 1 \r\n",
    "model.add(Dense(8, activation ='relu' ) )  # Hidden Layer 2\r\n",
    "model.add(Dense(1, activation= 'sigmoid') ) # Output layer\r\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\r\n",
    "loss = 'binary_crossentropy', #이진분류의 loss 함수는 binary_crossentropy, 범주형분류는 categorycal_crossentropy\r\n",
    "optimizer = 'adam',\r\n",
    "metrics = ['accuracy']\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델학습\r\n",
    "history = model.fit(\r\n",
    "    X_train, y_train, \r\n",
    "    validation_split= 0.2, #테스트해보는 셋 지정\r\n",
    "    epochs= 200, #epochs가 너무 크면 과대적합의 위험이 있다.\r\n",
    "    batch_size=50, #한번에 처리할 수 있는 양을 지정\r\n",
    "    verbose= 0\r\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5690 - accuracy: 0.7448\n",
      "정확도: 0.744792\n"
     ]
    }
   ],
   "source": [
    "acc = model.evaluate(X_test, y_test)\r\n",
    "print(f'정확도: {acc[1]:4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 30/1, rmsprop, 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 30)                270       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\r\n",
    "model2.add(Dense(30,input_shape=(8, ), activation ='relu' ) ) # Hidden Layer 1 \r\n",
    "model2.add(Dense(1, activation= 'sigmoid') ) # Output layer\r\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(\r\n",
    "    loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy']\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 43.5360 - accuracy: 0.3326 - val_loss: 30.3869 - val_accuracy: 0.4138\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 30.3665 - accuracy: 0.3348 - val_loss: 20.9488 - val_accuracy: 0.4138\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19.7486 - accuracy: 0.3413 - val_loss: 11.9332 - val_accuracy: 0.4310\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10.1816 - accuracy: 0.3783 - val_loss: 5.0479 - val_accuracy: 0.5086\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.9305 - accuracy: 0.5413 - val_loss: 2.6984 - val_accuracy: 0.5603\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.3396 - accuracy: 0.5739 - val_loss: 2.4000 - val_accuracy: 0.5517\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.1098 - accuracy: 0.5783 - val_loss: 2.3204 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.9274 - accuracy: 0.5826 - val_loss: 2.5252 - val_accuracy: 0.5517\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.9238 - accuracy: 0.5435 - val_loss: 2.0529 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6890 - accuracy: 0.5543 - val_loss: 1.8638 - val_accuracy: 0.5172\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.5597 - accuracy: 0.5717 - val_loss: 1.7898 - val_accuracy: 0.5431\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.4942 - accuracy: 0.5435 - val_loss: 1.7042 - val_accuracy: 0.4914\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.3488 - accuracy: 0.5761 - val_loss: 1.4839 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.2863 - accuracy: 0.5674 - val_loss: 1.7715 - val_accuracy: 0.5345\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.1703 - accuracy: 0.5870 - val_loss: 1.4942 - val_accuracy: 0.4741\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1874 - accuracy: 0.5652 - val_loss: 1.4051 - val_accuracy: 0.4828\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1377 - accuracy: 0.5435 - val_loss: 1.3863 - val_accuracy: 0.5259\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0945 - accuracy: 0.5761 - val_loss: 1.2882 - val_accuracy: 0.5086\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0412 - accuracy: 0.5783 - val_loss: 1.6065 - val_accuracy: 0.5345\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0406 - accuracy: 0.6152 - val_loss: 1.1329 - val_accuracy: 0.5259\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0133 - accuracy: 0.5783 - val_loss: 1.6991 - val_accuracy: 0.5172\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0529 - accuracy: 0.6174 - val_loss: 1.1343 - val_accuracy: 0.5172\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9165 - accuracy: 0.6022 - val_loss: 1.4096 - val_accuracy: 0.5086\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9280 - accuracy: 0.6239 - val_loss: 1.2608 - val_accuracy: 0.5172\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8748 - accuracy: 0.6326 - val_loss: 1.0255 - val_accuracy: 0.5517\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9202 - accuracy: 0.6261 - val_loss: 1.3963 - val_accuracy: 0.5172\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8778 - accuracy: 0.6261 - val_loss: 1.0582 - val_accuracy: 0.5690\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8555 - accuracy: 0.6304 - val_loss: 1.3832 - val_accuracy: 0.5431\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8534 - accuracy: 0.6239 - val_loss: 0.9339 - val_accuracy: 0.5517\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8145 - accuracy: 0.6196 - val_loss: 0.9752 - val_accuracy: 0.5431\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7975 - accuracy: 0.6130 - val_loss: 0.8742 - val_accuracy: 0.6034\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7563 - accuracy: 0.6522 - val_loss: 1.0432 - val_accuracy: 0.5603\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7585 - accuracy: 0.6478 - val_loss: 1.6343 - val_accuracy: 0.4741\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8856 - accuracy: 0.6000 - val_loss: 1.0847 - val_accuracy: 0.5345\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7804 - accuracy: 0.6109 - val_loss: 1.0535 - val_accuracy: 0.5431\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7430 - accuracy: 0.6152 - val_loss: 1.4744 - val_accuracy: 0.5776\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8508 - accuracy: 0.6217 - val_loss: 0.9650 - val_accuracy: 0.5345\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7363 - accuracy: 0.6457 - val_loss: 0.9394 - val_accuracy: 0.5690\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7231 - accuracy: 0.6326 - val_loss: 0.9891 - val_accuracy: 0.5776\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7315 - accuracy: 0.6522 - val_loss: 0.9506 - val_accuracy: 0.5517\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7198 - accuracy: 0.6522 - val_loss: 0.9888 - val_accuracy: 0.5086\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6973 - accuracy: 0.6870 - val_loss: 1.3820 - val_accuracy: 0.5776\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7248 - accuracy: 0.6891 - val_loss: 0.8148 - val_accuracy: 0.6121\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6969 - accuracy: 0.6391 - val_loss: 1.2622 - val_accuracy: 0.5776\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7173 - accuracy: 0.6717 - val_loss: 0.8073 - val_accuracy: 0.5776\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7286 - accuracy: 0.6522 - val_loss: 0.8005 - val_accuracy: 0.6293\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7266 - accuracy: 0.6326 - val_loss: 0.9072 - val_accuracy: 0.5517\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7354 - accuracy: 0.6522 - val_loss: 0.8319 - val_accuracy: 0.5862\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.6609 - val_loss: 0.9527 - val_accuracy: 0.5690\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6316 - accuracy: 0.6761 - val_loss: 1.1332 - val_accuracy: 0.5345\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6997 - accuracy: 0.6478 - val_loss: 0.7132 - val_accuracy: 0.6466\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6416 - accuracy: 0.6609 - val_loss: 0.8891 - val_accuracy: 0.5776\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6670 - accuracy: 0.6826 - val_loss: 0.7346 - val_accuracy: 0.6293\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6804 - val_loss: 0.9935 - val_accuracy: 0.5862\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6680 - accuracy: 0.6848 - val_loss: 0.8013 - val_accuracy: 0.6034\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6730 - accuracy: 0.6870 - val_loss: 0.8525 - val_accuracy: 0.5776\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.7000 - val_loss: 0.8880 - val_accuracy: 0.5862\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.6674 - val_loss: 0.7205 - val_accuracy: 0.6207\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6723 - accuracy: 0.6804 - val_loss: 1.0021 - val_accuracy: 0.5172\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.6935 - val_loss: 0.7468 - val_accuracy: 0.6466\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6116 - accuracy: 0.6870 - val_loss: 0.7710 - val_accuracy: 0.5776\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6287 - accuracy: 0.7043 - val_loss: 0.9951 - val_accuracy: 0.5172\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6527 - accuracy: 0.6630 - val_loss: 0.7528 - val_accuracy: 0.6121\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5887 - accuracy: 0.7174 - val_loss: 1.2165 - val_accuracy: 0.5948\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6627 - accuracy: 0.6848 - val_loss: 0.7379 - val_accuracy: 0.6207\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6200 - accuracy: 0.7065 - val_loss: 0.8299 - val_accuracy: 0.5948\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5858 - accuracy: 0.7239 - val_loss: 0.6870 - val_accuracy: 0.6466\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6370 - accuracy: 0.7000 - val_loss: 0.9791 - val_accuracy: 0.6207\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6299 - accuracy: 0.7130 - val_loss: 0.6718 - val_accuracy: 0.6724\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6294 - accuracy: 0.6761 - val_loss: 0.8168 - val_accuracy: 0.6121\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6321 - accuracy: 0.7065 - val_loss: 0.7324 - val_accuracy: 0.6207\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5876 - accuracy: 0.7152 - val_loss: 0.7093 - val_accuracy: 0.6379\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5981 - accuracy: 0.7174 - val_loss: 1.2235 - val_accuracy: 0.4741\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.6761 - val_loss: 0.6732 - val_accuracy: 0.6466\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6087 - accuracy: 0.6891 - val_loss: 1.3998 - val_accuracy: 0.5776\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.7283 - val_loss: 1.1142 - val_accuracy: 0.5776\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5629 - accuracy: 0.7283 - val_loss: 1.3470 - val_accuracy: 0.4397\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6679 - accuracy: 0.6826 - val_loss: 0.6562 - val_accuracy: 0.6810\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6459 - accuracy: 0.6913 - val_loss: 0.7201 - val_accuracy: 0.6379\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6387 - accuracy: 0.6870 - val_loss: 0.6380 - val_accuracy: 0.6810\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.7304 - val_loss: 0.7960 - val_accuracy: 0.5603\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.7196 - val_loss: 0.7794 - val_accuracy: 0.6207\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7217 - val_loss: 0.9058 - val_accuracy: 0.5345\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6183 - accuracy: 0.7022 - val_loss: 0.6656 - val_accuracy: 0.6121\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.7109 - val_loss: 0.7917 - val_accuracy: 0.6293\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.7326 - val_loss: 1.0324 - val_accuracy: 0.5948\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5796 - accuracy: 0.7283 - val_loss: 0.8001 - val_accuracy: 0.6207\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6318 - accuracy: 0.7000 - val_loss: 0.6567 - val_accuracy: 0.6293\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7478 - val_loss: 0.7857 - val_accuracy: 0.6293\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5867 - accuracy: 0.7413 - val_loss: 0.6956 - val_accuracy: 0.6810\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.7065 - val_loss: 0.6960 - val_accuracy: 0.6466\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7391 - val_loss: 0.8254 - val_accuracy: 0.6207\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6052 - accuracy: 0.6935 - val_loss: 0.7291 - val_accuracy: 0.6293\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6116 - accuracy: 0.7065 - val_loss: 0.6897 - val_accuracy: 0.6293\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7413 - val_loss: 0.6802 - val_accuracy: 0.6552\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.6891 - val_loss: 0.7944 - val_accuracy: 0.6207\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5617 - accuracy: 0.7065 - val_loss: 0.6922 - val_accuracy: 0.6293\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5941 - accuracy: 0.7043 - val_loss: 0.6258 - val_accuracy: 0.6638\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6015 - accuracy: 0.7326 - val_loss: 0.9692 - val_accuracy: 0.5172\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6458 - accuracy: 0.7087 - val_loss: 0.8666 - val_accuracy: 0.6121\n"
     ]
    }
   ],
   "source": [
    "# 모델학습\r\n",
    "history2 = model2.fit(\r\n",
    "    X_train, y_train, \r\n",
    "    validation_split= 0.2, #테스트해보는 셋 지정\r\n",
    "    epochs= 100, #epochs가 너무 크면 과대적합의 위험이 있다.\r\n",
    "    batch_size=50, #한번에 처리할 수 있는 양을 지정\r\n",
    "    verbose= 1\r\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7539 - accuracy: 0.6927\n",
      "정확도: 0.692708\n"
     ]
    }
   ],
   "source": [
    "acc = model2.evaluate(X_test, y_test)\r\n",
    "print(f'정확도: {acc[1]:4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 24/12/8/1 layers, 200 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 24)                216       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 629\n",
      "Trainable params: 629\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\r\n",
    "model3.add(Dense(24, input_shape=(8,), activation='relu'))\r\n",
    "model3.add(Dense(12, activation='relu'))\r\n",
    "model3.add(Dense(8, activation='relu'))\r\n",
    "model3.add(Dense(1, activation='sigmoid'))\r\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(\r\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 - 0s - loss: 10.5444 - accuracy: 0.3326 - val_loss: 6.8493 - val_accuracy: 0.4138\n",
      "Epoch 2/200\n",
      "10/10 - 0s - loss: 6.6367 - accuracy: 0.3348 - val_loss: 3.7411 - val_accuracy: 0.4224\n",
      "Epoch 3/200\n",
      "10/10 - 0s - loss: 3.2617 - accuracy: 0.3457 - val_loss: 1.6477 - val_accuracy: 0.4224\n",
      "Epoch 4/200\n",
      "10/10 - 0s - loss: 1.5858 - accuracy: 0.4087 - val_loss: 1.1279 - val_accuracy: 0.4569\n",
      "Epoch 5/200\n",
      "10/10 - 0s - loss: 1.0471 - accuracy: 0.5435 - val_loss: 0.9885 - val_accuracy: 0.5603\n",
      "Epoch 6/200\n",
      "10/10 - 0s - loss: 0.8512 - accuracy: 0.6348 - val_loss: 0.7958 - val_accuracy: 0.5345\n",
      "Epoch 7/200\n",
      "10/10 - 0s - loss: 0.7630 - accuracy: 0.6152 - val_loss: 0.7620 - val_accuracy: 0.5259\n",
      "Epoch 8/200\n",
      "10/10 - 0s - loss: 0.7297 - accuracy: 0.6174 - val_loss: 0.7272 - val_accuracy: 0.5690\n",
      "Epoch 9/200\n",
      "10/10 - 0s - loss: 0.7092 - accuracy: 0.6217 - val_loss: 0.7099 - val_accuracy: 0.5948\n",
      "Epoch 10/200\n",
      "10/10 - 0s - loss: 0.6967 - accuracy: 0.6457 - val_loss: 0.7150 - val_accuracy: 0.5776\n",
      "Epoch 11/200\n",
      "10/10 - 0s - loss: 0.6894 - accuracy: 0.6652 - val_loss: 0.7322 - val_accuracy: 0.5948\n",
      "Epoch 12/200\n",
      "10/10 - 0s - loss: 0.6856 - accuracy: 0.6609 - val_loss: 0.7250 - val_accuracy: 0.5862\n",
      "Epoch 13/200\n",
      "10/10 - 0s - loss: 0.6816 - accuracy: 0.6652 - val_loss: 0.7094 - val_accuracy: 0.5776\n",
      "Epoch 14/200\n",
      "10/10 - 0s - loss: 0.6776 - accuracy: 0.6587 - val_loss: 0.7063 - val_accuracy: 0.5776\n",
      "Epoch 15/200\n",
      "10/10 - 0s - loss: 0.6754 - accuracy: 0.6674 - val_loss: 0.7162 - val_accuracy: 0.5948\n",
      "Epoch 16/200\n",
      "10/10 - 0s - loss: 0.6720 - accuracy: 0.6696 - val_loss: 0.7086 - val_accuracy: 0.5862\n",
      "Epoch 17/200\n",
      "10/10 - 0s - loss: 0.6694 - accuracy: 0.6674 - val_loss: 0.7028 - val_accuracy: 0.5862\n",
      "Epoch 18/200\n",
      "10/10 - 0s - loss: 0.6683 - accuracy: 0.6609 - val_loss: 0.6938 - val_accuracy: 0.5776\n",
      "Epoch 19/200\n",
      "10/10 - 0s - loss: 0.6668 - accuracy: 0.6652 - val_loss: 0.7044 - val_accuracy: 0.5862\n",
      "Epoch 20/200\n",
      "10/10 - 0s - loss: 0.6645 - accuracy: 0.6674 - val_loss: 0.7123 - val_accuracy: 0.5948\n",
      "Epoch 21/200\n",
      "10/10 - 0s - loss: 0.6623 - accuracy: 0.6630 - val_loss: 0.6973 - val_accuracy: 0.5862\n",
      "Epoch 22/200\n",
      "10/10 - 0s - loss: 0.6606 - accuracy: 0.6630 - val_loss: 0.7019 - val_accuracy: 0.5862\n",
      "Epoch 23/200\n",
      "10/10 - 0s - loss: 0.6540 - accuracy: 0.6674 - val_loss: 0.6874 - val_accuracy: 0.5862\n",
      "Epoch 24/200\n",
      "10/10 - 0s - loss: 0.6491 - accuracy: 0.6696 - val_loss: 0.6910 - val_accuracy: 0.6034\n",
      "Epoch 25/200\n",
      "10/10 - 0s - loss: 0.6471 - accuracy: 0.6739 - val_loss: 0.6943 - val_accuracy: 0.5948\n",
      "Epoch 26/200\n",
      "10/10 - 0s - loss: 0.6433 - accuracy: 0.6717 - val_loss: 0.6823 - val_accuracy: 0.5948\n",
      "Epoch 27/200\n",
      "10/10 - 0s - loss: 0.6405 - accuracy: 0.6674 - val_loss: 0.6830 - val_accuracy: 0.5776\n",
      "Epoch 28/200\n",
      "10/10 - 0s - loss: 0.6410 - accuracy: 0.6696 - val_loss: 0.6747 - val_accuracy: 0.5862\n",
      "Epoch 29/200\n",
      "10/10 - 0s - loss: 0.6404 - accuracy: 0.6674 - val_loss: 0.6876 - val_accuracy: 0.5776\n",
      "Epoch 30/200\n",
      "10/10 - 0s - loss: 0.6372 - accuracy: 0.6717 - val_loss: 0.6767 - val_accuracy: 0.5862\n",
      "Epoch 31/200\n",
      "10/10 - 0s - loss: 0.6361 - accuracy: 0.6696 - val_loss: 0.6664 - val_accuracy: 0.5948\n",
      "Epoch 32/200\n",
      "10/10 - 0s - loss: 0.6384 - accuracy: 0.6696 - val_loss: 0.6685 - val_accuracy: 0.5948\n",
      "Epoch 33/200\n",
      "10/10 - 0s - loss: 0.6376 - accuracy: 0.6717 - val_loss: 0.6743 - val_accuracy: 0.5862\n",
      "Epoch 34/200\n",
      "10/10 - 0s - loss: 0.6333 - accuracy: 0.6696 - val_loss: 0.6678 - val_accuracy: 0.5862\n",
      "Epoch 35/200\n",
      "10/10 - 0s - loss: 0.6346 - accuracy: 0.6696 - val_loss: 0.6679 - val_accuracy: 0.5862\n",
      "Epoch 36/200\n",
      "10/10 - 0s - loss: 0.6343 - accuracy: 0.6674 - val_loss: 0.6777 - val_accuracy: 0.5776\n",
      "Epoch 37/200\n",
      "10/10 - 0s - loss: 0.6315 - accuracy: 0.6696 - val_loss: 0.6775 - val_accuracy: 0.5862\n",
      "Epoch 38/200\n",
      "10/10 - 0s - loss: 0.6331 - accuracy: 0.6652 - val_loss: 0.6733 - val_accuracy: 0.5862\n",
      "Epoch 39/200\n",
      "10/10 - 0s - loss: 0.6374 - accuracy: 0.6696 - val_loss: 0.6633 - val_accuracy: 0.5948\n",
      "Epoch 40/200\n",
      "10/10 - 0s - loss: 0.6323 - accuracy: 0.6717 - val_loss: 0.6864 - val_accuracy: 0.5776\n",
      "Epoch 41/200\n",
      "10/10 - 0s - loss: 0.6333 - accuracy: 0.6674 - val_loss: 0.6645 - val_accuracy: 0.5862\n",
      "Epoch 42/200\n",
      "10/10 - 0s - loss: 0.6309 - accuracy: 0.6674 - val_loss: 0.6713 - val_accuracy: 0.5948\n",
      "Epoch 43/200\n",
      "10/10 - 0s - loss: 0.6279 - accuracy: 0.6652 - val_loss: 0.6840 - val_accuracy: 0.5776\n",
      "Epoch 44/200\n",
      "10/10 - 0s - loss: 0.6368 - accuracy: 0.6674 - val_loss: 0.6644 - val_accuracy: 0.5948\n",
      "Epoch 45/200\n",
      "10/10 - 0s - loss: 0.6288 - accuracy: 0.6739 - val_loss: 0.6684 - val_accuracy: 0.5948\n",
      "Epoch 46/200\n",
      "10/10 - 0s - loss: 0.6268 - accuracy: 0.6674 - val_loss: 0.6790 - val_accuracy: 0.5862\n",
      "Epoch 47/200\n",
      "10/10 - 0s - loss: 0.6280 - accuracy: 0.6674 - val_loss: 0.6612 - val_accuracy: 0.5948\n",
      "Epoch 48/200\n",
      "10/10 - 0s - loss: 0.6257 - accuracy: 0.6739 - val_loss: 0.6608 - val_accuracy: 0.5948\n",
      "Epoch 49/200\n",
      "10/10 - 0s - loss: 0.6257 - accuracy: 0.6674 - val_loss: 0.6753 - val_accuracy: 0.5862\n",
      "Epoch 50/200\n",
      "10/10 - 0s - loss: 0.6244 - accuracy: 0.6674 - val_loss: 0.6664 - val_accuracy: 0.5948\n",
      "Epoch 51/200\n",
      "10/10 - 0s - loss: 0.6312 - accuracy: 0.6652 - val_loss: 0.6539 - val_accuracy: 0.6034\n",
      "Epoch 52/200\n",
      "10/10 - 0s - loss: 0.6267 - accuracy: 0.6717 - val_loss: 0.6774 - val_accuracy: 0.5862\n",
      "Epoch 53/200\n",
      "10/10 - 0s - loss: 0.6243 - accuracy: 0.6674 - val_loss: 0.6745 - val_accuracy: 0.5862\n",
      "Epoch 54/200\n",
      "10/10 - 0s - loss: 0.6247 - accuracy: 0.6630 - val_loss: 0.6592 - val_accuracy: 0.6034\n",
      "Epoch 55/200\n",
      "10/10 - 0s - loss: 0.6253 - accuracy: 0.6696 - val_loss: 0.6615 - val_accuracy: 0.5948\n",
      "Epoch 56/200\n",
      "10/10 - 0s - loss: 0.6246 - accuracy: 0.6717 - val_loss: 0.6801 - val_accuracy: 0.5862\n",
      "Epoch 57/200\n",
      "10/10 - 0s - loss: 0.6183 - accuracy: 0.6696 - val_loss: 0.6657 - val_accuracy: 0.5948\n",
      "Epoch 58/200\n",
      "10/10 - 0s - loss: 0.6267 - accuracy: 0.6696 - val_loss: 0.6573 - val_accuracy: 0.5948\n",
      "Epoch 59/200\n",
      "10/10 - 0s - loss: 0.6224 - accuracy: 0.6696 - val_loss: 0.6699 - val_accuracy: 0.5948\n",
      "Epoch 60/200\n",
      "10/10 - 0s - loss: 0.6205 - accuracy: 0.6696 - val_loss: 0.6659 - val_accuracy: 0.5948\n",
      "Epoch 61/200\n",
      "10/10 - 0s - loss: 0.6229 - accuracy: 0.6696 - val_loss: 0.6645 - val_accuracy: 0.5948\n",
      "Epoch 62/200\n",
      "10/10 - 0s - loss: 0.6208 - accuracy: 0.6717 - val_loss: 0.6710 - val_accuracy: 0.5948\n",
      "Epoch 63/200\n",
      "10/10 - 0s - loss: 0.6177 - accuracy: 0.6717 - val_loss: 0.6677 - val_accuracy: 0.5948\n",
      "Epoch 64/200\n",
      "10/10 - 0s - loss: 0.6235 - accuracy: 0.6717 - val_loss: 0.6754 - val_accuracy: 0.5862\n",
      "Epoch 65/200\n",
      "10/10 - 0s - loss: 0.6287 - accuracy: 0.6674 - val_loss: 0.6853 - val_accuracy: 0.5862\n",
      "Epoch 66/200\n",
      "10/10 - 0s - loss: 0.6225 - accuracy: 0.6696 - val_loss: 0.6619 - val_accuracy: 0.5948\n",
      "Epoch 67/200\n",
      "10/10 - 0s - loss: 0.6168 - accuracy: 0.6717 - val_loss: 0.6713 - val_accuracy: 0.5948\n",
      "Epoch 68/200\n",
      "10/10 - 0s - loss: 0.6179 - accuracy: 0.6674 - val_loss: 0.6690 - val_accuracy: 0.5948\n",
      "Epoch 69/200\n",
      "10/10 - 0s - loss: 0.6179 - accuracy: 0.6674 - val_loss: 0.6720 - val_accuracy: 0.5948\n",
      "Epoch 70/200\n",
      "10/10 - 0s - loss: 0.6198 - accuracy: 0.6696 - val_loss: 0.6712 - val_accuracy: 0.5862\n",
      "Epoch 71/200\n",
      "10/10 - 0s - loss: 0.6158 - accuracy: 0.6652 - val_loss: 0.6824 - val_accuracy: 0.5862\n",
      "Epoch 72/200\n",
      "10/10 - 0s - loss: 0.6157 - accuracy: 0.6674 - val_loss: 0.6659 - val_accuracy: 0.5948\n",
      "Epoch 73/200\n",
      "10/10 - 0s - loss: 0.6164 - accuracy: 0.6739 - val_loss: 0.6613 - val_accuracy: 0.5948\n",
      "Epoch 74/200\n",
      "10/10 - 0s - loss: 0.6200 - accuracy: 0.6696 - val_loss: 0.6545 - val_accuracy: 0.5948\n",
      "Epoch 75/200\n",
      "10/10 - 0s - loss: 0.6178 - accuracy: 0.6652 - val_loss: 0.6702 - val_accuracy: 0.5948\n",
      "Epoch 76/200\n",
      "10/10 - 0s - loss: 0.6174 - accuracy: 0.6674 - val_loss: 0.6827 - val_accuracy: 0.5862\n",
      "Epoch 77/200\n",
      "10/10 - 0s - loss: 0.6153 - accuracy: 0.6652 - val_loss: 0.6709 - val_accuracy: 0.5862\n",
      "Epoch 78/200\n",
      "10/10 - 0s - loss: 0.6249 - accuracy: 0.6739 - val_loss: 0.6570 - val_accuracy: 0.6034\n",
      "Epoch 79/200\n",
      "10/10 - 0s - loss: 0.6201 - accuracy: 0.6717 - val_loss: 0.6625 - val_accuracy: 0.5948\n",
      "Epoch 80/200\n",
      "10/10 - 0s - loss: 0.6208 - accuracy: 0.6696 - val_loss: 0.6679 - val_accuracy: 0.5862\n",
      "Epoch 81/200\n",
      "10/10 - 0s - loss: 0.6114 - accuracy: 0.6717 - val_loss: 0.6561 - val_accuracy: 0.5948\n",
      "Epoch 82/200\n",
      "10/10 - 0s - loss: 0.6131 - accuracy: 0.6674 - val_loss: 0.6575 - val_accuracy: 0.5948\n",
      "Epoch 83/200\n",
      "10/10 - 0s - loss: 0.6115 - accuracy: 0.6696 - val_loss: 0.6659 - val_accuracy: 0.5948\n",
      "Epoch 84/200\n",
      "10/10 - 0s - loss: 0.6104 - accuracy: 0.6717 - val_loss: 0.6610 - val_accuracy: 0.5948\n",
      "Epoch 85/200\n",
      "10/10 - 0s - loss: 0.6127 - accuracy: 0.6717 - val_loss: 0.6642 - val_accuracy: 0.5948\n",
      "Epoch 86/200\n",
      "10/10 - 0s - loss: 0.6104 - accuracy: 0.6717 - val_loss: 0.6699 - val_accuracy: 0.5948\n",
      "Epoch 87/200\n",
      "10/10 - 0s - loss: 0.6099 - accuracy: 0.6717 - val_loss: 0.6636 - val_accuracy: 0.5948\n",
      "Epoch 88/200\n",
      "10/10 - 0s - loss: 0.6092 - accuracy: 0.6717 - val_loss: 0.6605 - val_accuracy: 0.5948\n",
      "Epoch 89/200\n",
      "10/10 - 0s - loss: 0.6106 - accuracy: 0.6696 - val_loss: 0.6672 - val_accuracy: 0.5948\n",
      "Epoch 90/200\n",
      "10/10 - 0s - loss: 0.6100 - accuracy: 0.6717 - val_loss: 0.6611 - val_accuracy: 0.5948\n",
      "Epoch 91/200\n",
      "10/10 - 0s - loss: 0.6120 - accuracy: 0.6696 - val_loss: 0.6538 - val_accuracy: 0.6293\n",
      "Epoch 92/200\n",
      "10/10 - 0s - loss: 0.6094 - accuracy: 0.6717 - val_loss: 0.6641 - val_accuracy: 0.5948\n",
      "Epoch 93/200\n",
      "10/10 - 0s - loss: 0.6071 - accuracy: 0.6739 - val_loss: 0.6683 - val_accuracy: 0.5948\n",
      "Epoch 94/200\n",
      "10/10 - 0s - loss: 0.6073 - accuracy: 0.6696 - val_loss: 0.6756 - val_accuracy: 0.5862\n",
      "Epoch 95/200\n",
      "10/10 - 0s - loss: 0.6173 - accuracy: 0.6696 - val_loss: 0.6640 - val_accuracy: 0.5948\n",
      "Epoch 96/200\n",
      "10/10 - 0s - loss: 0.6178 - accuracy: 0.6717 - val_loss: 0.6753 - val_accuracy: 0.5862\n",
      "Epoch 97/200\n",
      "10/10 - 0s - loss: 0.6083 - accuracy: 0.6739 - val_loss: 0.6653 - val_accuracy: 0.6034\n",
      "Epoch 98/200\n",
      "10/10 - 0s - loss: 0.6093 - accuracy: 0.6761 - val_loss: 0.6652 - val_accuracy: 0.6034\n",
      "Epoch 99/200\n",
      "10/10 - 0s - loss: 0.6067 - accuracy: 0.6739 - val_loss: 0.6661 - val_accuracy: 0.6034\n",
      "Epoch 100/200\n",
      "10/10 - 0s - loss: 0.6056 - accuracy: 0.6696 - val_loss: 0.6613 - val_accuracy: 0.6034\n",
      "Epoch 101/200\n",
      "10/10 - 0s - loss: 0.6088 - accuracy: 0.6674 - val_loss: 0.6795 - val_accuracy: 0.5862\n",
      "Epoch 102/200\n",
      "10/10 - 0s - loss: 0.6076 - accuracy: 0.6674 - val_loss: 0.6546 - val_accuracy: 0.6207\n",
      "Epoch 103/200\n",
      "10/10 - 0s - loss: 0.6125 - accuracy: 0.6717 - val_loss: 0.6605 - val_accuracy: 0.6034\n",
      "Epoch 104/200\n",
      "10/10 - 0s - loss: 0.6100 - accuracy: 0.6696 - val_loss: 0.6645 - val_accuracy: 0.5948\n",
      "Epoch 105/200\n",
      "10/10 - 0s - loss: 0.6142 - accuracy: 0.6717 - val_loss: 0.6661 - val_accuracy: 0.5948\n",
      "Epoch 106/200\n",
      "10/10 - 0s - loss: 0.6058 - accuracy: 0.6761 - val_loss: 0.6634 - val_accuracy: 0.6034\n",
      "Epoch 107/200\n",
      "10/10 - 0s - loss: 0.6047 - accuracy: 0.6761 - val_loss: 0.6658 - val_accuracy: 0.6034\n",
      "Epoch 108/200\n",
      "10/10 - 0s - loss: 0.6043 - accuracy: 0.6696 - val_loss: 0.6645 - val_accuracy: 0.6034\n",
      "Epoch 109/200\n",
      "10/10 - 0s - loss: 0.6170 - accuracy: 0.6739 - val_loss: 0.6532 - val_accuracy: 0.6207\n",
      "Epoch 110/200\n",
      "10/10 - 0s - loss: 0.6198 - accuracy: 0.6674 - val_loss: 0.6767 - val_accuracy: 0.5862\n",
      "Epoch 111/200\n",
      "10/10 - 0s - loss: 0.6150 - accuracy: 0.6652 - val_loss: 0.6536 - val_accuracy: 0.6207\n",
      "Epoch 112/200\n",
      "10/10 - 0s - loss: 0.6047 - accuracy: 0.6652 - val_loss: 0.6745 - val_accuracy: 0.5862\n",
      "Epoch 113/200\n",
      "10/10 - 0s - loss: 0.6020 - accuracy: 0.6717 - val_loss: 0.6574 - val_accuracy: 0.6034\n",
      "Epoch 114/200\n",
      "10/10 - 0s - loss: 0.6073 - accuracy: 0.6739 - val_loss: 0.6577 - val_accuracy: 0.6034\n",
      "Epoch 115/200\n",
      "10/10 - 0s - loss: 0.6113 - accuracy: 0.6739 - val_loss: 0.6663 - val_accuracy: 0.5948\n",
      "Epoch 116/200\n",
      "10/10 - 0s - loss: 0.6006 - accuracy: 0.6761 - val_loss: 0.6595 - val_accuracy: 0.6034\n",
      "Epoch 117/200\n",
      "10/10 - 0s - loss: 0.6126 - accuracy: 0.6652 - val_loss: 0.6496 - val_accuracy: 0.6207\n",
      "Epoch 118/200\n",
      "10/10 - 0s - loss: 0.5985 - accuracy: 0.6696 - val_loss: 0.6552 - val_accuracy: 0.6034\n",
      "Epoch 119/200\n",
      "10/10 - 0s - loss: 0.6057 - accuracy: 0.6696 - val_loss: 0.6632 - val_accuracy: 0.5948\n",
      "Epoch 120/200\n",
      "10/10 - 0s - loss: 0.6053 - accuracy: 0.6761 - val_loss: 0.6728 - val_accuracy: 0.6034\n",
      "Epoch 121/200\n",
      "10/10 - 0s - loss: 0.6000 - accuracy: 0.6674 - val_loss: 0.6453 - val_accuracy: 0.6293\n",
      "Epoch 122/200\n",
      "10/10 - 0s - loss: 0.6006 - accuracy: 0.6696 - val_loss: 0.6562 - val_accuracy: 0.6034\n",
      "Epoch 123/200\n",
      "10/10 - 0s - loss: 0.6034 - accuracy: 0.6717 - val_loss: 0.6710 - val_accuracy: 0.5862\n",
      "Epoch 124/200\n",
      "10/10 - 0s - loss: 0.5994 - accuracy: 0.6696 - val_loss: 0.6421 - val_accuracy: 0.6207\n",
      "Epoch 125/200\n",
      "10/10 - 0s - loss: 0.6071 - accuracy: 0.6717 - val_loss: 0.6442 - val_accuracy: 0.6293\n",
      "Epoch 126/200\n",
      "10/10 - 0s - loss: 0.5998 - accuracy: 0.6565 - val_loss: 0.6683 - val_accuracy: 0.5948\n",
      "Epoch 127/200\n",
      "10/10 - 0s - loss: 0.5973 - accuracy: 0.6761 - val_loss: 0.6571 - val_accuracy: 0.6034\n",
      "Epoch 128/200\n",
      "10/10 - 0s - loss: 0.5947 - accuracy: 0.6674 - val_loss: 0.6593 - val_accuracy: 0.6207\n",
      "Epoch 129/200\n",
      "10/10 - 0s - loss: 0.5981 - accuracy: 0.6717 - val_loss: 0.6515 - val_accuracy: 0.6207\n",
      "Epoch 130/200\n",
      "10/10 - 0s - loss: 0.5943 - accuracy: 0.6652 - val_loss: 0.6766 - val_accuracy: 0.6034\n",
      "Epoch 131/200\n",
      "10/10 - 0s - loss: 0.5944 - accuracy: 0.6739 - val_loss: 0.6634 - val_accuracy: 0.6034\n",
      "Epoch 132/200\n",
      "10/10 - 0s - loss: 0.5926 - accuracy: 0.6739 - val_loss: 0.6737 - val_accuracy: 0.6034\n",
      "Epoch 133/200\n",
      "10/10 - 0s - loss: 0.5940 - accuracy: 0.6761 - val_loss: 0.6591 - val_accuracy: 0.6121\n",
      "Epoch 134/200\n",
      "10/10 - 0s - loss: 0.5925 - accuracy: 0.6696 - val_loss: 0.6635 - val_accuracy: 0.6034\n",
      "Epoch 135/200\n",
      "10/10 - 0s - loss: 0.5939 - accuracy: 0.6696 - val_loss: 0.6736 - val_accuracy: 0.6034\n",
      "Epoch 136/200\n",
      "10/10 - 0s - loss: 0.5888 - accuracy: 0.6717 - val_loss: 0.6585 - val_accuracy: 0.6207\n",
      "Epoch 137/200\n",
      "10/10 - 0s - loss: 0.5908 - accuracy: 0.6717 - val_loss: 0.6663 - val_accuracy: 0.6207\n",
      "Epoch 138/200\n",
      "10/10 - 0s - loss: 0.5911 - accuracy: 0.6717 - val_loss: 0.6678 - val_accuracy: 0.6293\n",
      "Epoch 139/200\n",
      "10/10 - 0s - loss: 0.5912 - accuracy: 0.6696 - val_loss: 0.6736 - val_accuracy: 0.6034\n",
      "Epoch 140/200\n",
      "10/10 - 0s - loss: 0.5884 - accuracy: 0.6674 - val_loss: 0.6707 - val_accuracy: 0.6293\n",
      "Epoch 141/200\n",
      "10/10 - 0s - loss: 0.5860 - accuracy: 0.6739 - val_loss: 0.6660 - val_accuracy: 0.6293\n",
      "Epoch 142/200\n",
      "10/10 - 0s - loss: 0.5858 - accuracy: 0.6739 - val_loss: 0.6706 - val_accuracy: 0.6293\n",
      "Epoch 143/200\n",
      "10/10 - 0s - loss: 0.5841 - accuracy: 0.6804 - val_loss: 0.6907 - val_accuracy: 0.5948\n",
      "Epoch 144/200\n",
      "10/10 - 0s - loss: 0.5878 - accuracy: 0.6674 - val_loss: 0.6754 - val_accuracy: 0.6034\n",
      "Epoch 145/200\n",
      "10/10 - 0s - loss: 0.5864 - accuracy: 0.6717 - val_loss: 0.6775 - val_accuracy: 0.6034\n",
      "Epoch 146/200\n",
      "10/10 - 0s - loss: 0.5862 - accuracy: 0.6717 - val_loss: 0.6620 - val_accuracy: 0.6293\n",
      "Epoch 147/200\n",
      "10/10 - 0s - loss: 0.5859 - accuracy: 0.6848 - val_loss: 0.6692 - val_accuracy: 0.6293\n",
      "Epoch 148/200\n",
      "10/10 - 0s - loss: 0.5827 - accuracy: 0.6739 - val_loss: 0.6689 - val_accuracy: 0.6293\n",
      "Epoch 149/200\n",
      "10/10 - 0s - loss: 0.5804 - accuracy: 0.6739 - val_loss: 0.6721 - val_accuracy: 0.6207\n",
      "Epoch 150/200\n",
      "10/10 - 0s - loss: 0.5803 - accuracy: 0.6783 - val_loss: 0.6737 - val_accuracy: 0.6207\n",
      "Epoch 151/200\n",
      "10/10 - 0s - loss: 0.5826 - accuracy: 0.6674 - val_loss: 0.6661 - val_accuracy: 0.6379\n",
      "Epoch 152/200\n",
      "10/10 - 0s - loss: 0.5903 - accuracy: 0.6783 - val_loss: 0.6689 - val_accuracy: 0.6207\n",
      "Epoch 153/200\n",
      "10/10 - 0s - loss: 0.5877 - accuracy: 0.6848 - val_loss: 0.6719 - val_accuracy: 0.6379\n",
      "Epoch 154/200\n",
      "10/10 - 0s - loss: 0.5790 - accuracy: 0.6652 - val_loss: 0.6733 - val_accuracy: 0.6207\n",
      "Epoch 155/200\n",
      "10/10 - 0s - loss: 0.5753 - accuracy: 0.6696 - val_loss: 0.6717 - val_accuracy: 0.6207\n",
      "Epoch 156/200\n",
      "10/10 - 0s - loss: 0.5732 - accuracy: 0.6761 - val_loss: 0.6753 - val_accuracy: 0.6379\n",
      "Epoch 157/200\n",
      "10/10 - 0s - loss: 0.5747 - accuracy: 0.6957 - val_loss: 0.6710 - val_accuracy: 0.6466\n",
      "Epoch 158/200\n",
      "10/10 - 0s - loss: 0.5760 - accuracy: 0.7174 - val_loss: 0.6752 - val_accuracy: 0.6379\n",
      "Epoch 159/200\n",
      "10/10 - 0s - loss: 0.5763 - accuracy: 0.6913 - val_loss: 0.6873 - val_accuracy: 0.5948\n",
      "Epoch 160/200\n",
      "10/10 - 0s - loss: 0.5752 - accuracy: 0.6674 - val_loss: 0.6898 - val_accuracy: 0.5948\n",
      "Epoch 161/200\n",
      "10/10 - 0s - loss: 0.5754 - accuracy: 0.6761 - val_loss: 0.6786 - val_accuracy: 0.5948\n",
      "Epoch 162/200\n",
      "10/10 - 0s - loss: 0.5711 - accuracy: 0.6891 - val_loss: 0.6727 - val_accuracy: 0.6207\n",
      "Epoch 163/200\n",
      "10/10 - 0s - loss: 0.5786 - accuracy: 0.7109 - val_loss: 0.6639 - val_accuracy: 0.6552\n",
      "Epoch 164/200\n",
      "10/10 - 0s - loss: 0.5710 - accuracy: 0.7043 - val_loss: 0.6736 - val_accuracy: 0.6034\n",
      "Epoch 165/200\n",
      "10/10 - 0s - loss: 0.5705 - accuracy: 0.6891 - val_loss: 0.6766 - val_accuracy: 0.5948\n",
      "Epoch 166/200\n",
      "10/10 - 0s - loss: 0.5697 - accuracy: 0.6913 - val_loss: 0.6714 - val_accuracy: 0.6466\n",
      "Epoch 167/200\n",
      "10/10 - 0s - loss: 0.5703 - accuracy: 0.6957 - val_loss: 0.6699 - val_accuracy: 0.6379\n",
      "Epoch 168/200\n",
      "10/10 - 0s - loss: 0.5771 - accuracy: 0.7174 - val_loss: 0.6667 - val_accuracy: 0.6552\n",
      "Epoch 169/200\n",
      "10/10 - 0s - loss: 0.5749 - accuracy: 0.6935 - val_loss: 0.6801 - val_accuracy: 0.6121\n",
      "Epoch 170/200\n",
      "10/10 - 0s - loss: 0.5704 - accuracy: 0.7022 - val_loss: 0.6679 - val_accuracy: 0.6379\n",
      "Epoch 171/200\n",
      "10/10 - 0s - loss: 0.5643 - accuracy: 0.7065 - val_loss: 0.6759 - val_accuracy: 0.6293\n",
      "Epoch 172/200\n",
      "10/10 - 0s - loss: 0.5659 - accuracy: 0.7022 - val_loss: 0.6705 - val_accuracy: 0.6293\n",
      "Epoch 173/200\n",
      "10/10 - 0s - loss: 0.5637 - accuracy: 0.7043 - val_loss: 0.6685 - val_accuracy: 0.6379\n",
      "Epoch 174/200\n",
      "10/10 - 0s - loss: 0.5637 - accuracy: 0.7152 - val_loss: 0.6699 - val_accuracy: 0.6379\n",
      "Epoch 175/200\n",
      "10/10 - 0s - loss: 0.5685 - accuracy: 0.6957 - val_loss: 0.6740 - val_accuracy: 0.6207\n",
      "Epoch 176/200\n",
      "10/10 - 0s - loss: 0.5773 - accuracy: 0.7152 - val_loss: 0.6669 - val_accuracy: 0.6724\n",
      "Epoch 177/200\n",
      "10/10 - 0s - loss: 0.5789 - accuracy: 0.6978 - val_loss: 0.6777 - val_accuracy: 0.5948\n",
      "Epoch 178/200\n",
      "10/10 - 0s - loss: 0.5637 - accuracy: 0.6891 - val_loss: 0.6830 - val_accuracy: 0.6121\n",
      "Epoch 179/200\n",
      "10/10 - 0s - loss: 0.5681 - accuracy: 0.7174 - val_loss: 0.6609 - val_accuracy: 0.6983\n",
      "Epoch 180/200\n",
      "10/10 - 0s - loss: 0.5667 - accuracy: 0.7065 - val_loss: 0.6722 - val_accuracy: 0.6379\n",
      "Epoch 181/200\n",
      "10/10 - 0s - loss: 0.5595 - accuracy: 0.7152 - val_loss: 0.6668 - val_accuracy: 0.6810\n",
      "Epoch 182/200\n",
      "10/10 - 0s - loss: 0.5591 - accuracy: 0.7174 - val_loss: 0.6678 - val_accuracy: 0.6379\n",
      "Epoch 183/200\n",
      "10/10 - 0s - loss: 0.5576 - accuracy: 0.7174 - val_loss: 0.6742 - val_accuracy: 0.6466\n",
      "Epoch 184/200\n",
      "10/10 - 0s - loss: 0.5633 - accuracy: 0.7174 - val_loss: 0.6648 - val_accuracy: 0.6638\n",
      "Epoch 185/200\n",
      "10/10 - 0s - loss: 0.5579 - accuracy: 0.7065 - val_loss: 0.6722 - val_accuracy: 0.6207\n",
      "Epoch 186/200\n",
      "10/10 - 0s - loss: 0.5571 - accuracy: 0.7152 - val_loss: 0.6658 - val_accuracy: 0.6724\n",
      "Epoch 187/200\n",
      "10/10 - 0s - loss: 0.5572 - accuracy: 0.7239 - val_loss: 0.6628 - val_accuracy: 0.6638\n",
      "Epoch 188/200\n",
      "10/10 - 0s - loss: 0.5560 - accuracy: 0.7217 - val_loss: 0.6661 - val_accuracy: 0.6638\n",
      "Epoch 189/200\n",
      "10/10 - 0s - loss: 0.5562 - accuracy: 0.7152 - val_loss: 0.6698 - val_accuracy: 0.6207\n",
      "Epoch 190/200\n",
      "10/10 - 0s - loss: 0.5579 - accuracy: 0.7109 - val_loss: 0.6715 - val_accuracy: 0.6207\n",
      "Epoch 191/200\n",
      "10/10 - 0s - loss: 0.5534 - accuracy: 0.7196 - val_loss: 0.6643 - val_accuracy: 0.6552\n",
      "Epoch 192/200\n",
      "10/10 - 0s - loss: 0.5571 - accuracy: 0.7326 - val_loss: 0.6708 - val_accuracy: 0.6724\n",
      "Epoch 193/200\n",
      "10/10 - 0s - loss: 0.5668 - accuracy: 0.7239 - val_loss: 0.6690 - val_accuracy: 0.6638\n",
      "Epoch 194/200\n",
      "10/10 - 0s - loss: 0.5730 - accuracy: 0.7043 - val_loss: 0.6664 - val_accuracy: 0.6638\n",
      "Epoch 195/200\n",
      "10/10 - 0s - loss: 0.5766 - accuracy: 0.7022 - val_loss: 0.6798 - val_accuracy: 0.5862\n",
      "Epoch 196/200\n",
      "10/10 - 0s - loss: 0.5728 - accuracy: 0.6848 - val_loss: 0.6799 - val_accuracy: 0.5948\n",
      "Epoch 197/200\n",
      "10/10 - 0s - loss: 0.5609 - accuracy: 0.6935 - val_loss: 0.6749 - val_accuracy: 0.6207\n",
      "Epoch 198/200\n",
      "10/10 - 0s - loss: 0.5575 - accuracy: 0.7239 - val_loss: 0.6608 - val_accuracy: 0.6724\n",
      "Epoch 199/200\n",
      "10/10 - 0s - loss: 0.5567 - accuracy: 0.7304 - val_loss: 0.6651 - val_accuracy: 0.6638\n",
      "Epoch 200/200\n",
      "10/10 - 0s - loss: 0.5502 - accuracy: 0.7152 - val_loss: 0.6748 - val_accuracy: 0.6466\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(\r\n",
    "    X_train, y_train, validation_split=0.2,\r\n",
    "    epochs=200, batch_size=50, verbose=2\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 831us/step - loss: 0.5563 - accuracy: 0.7448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5562655329704285, 0.7447916865348816]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMaxScaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "scaler = MinMaxScaler()\r\n",
    "X_scaled = scaler.fit_transform(df.iloc[:,:-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\r\n",
    "    X_scaled, df.iloc[:,-1].values, \r\n",
    "    stratify=df.iloc[:,-1].values, random_state=seed\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\r\n",
    "model4.add(Dense(12, input_dim=8, activation='relu'))\r\n",
    "model4.add(Dense(8, activation='relu'))\r\n",
    "model4.add(Dense(1, activation='sigmoid'))\r\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(\r\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 - 0s - loss: 0.6904 - accuracy: 0.5935 - val_loss: 0.6850 - val_accuracy: 0.6034\n",
      "Epoch 2/200\n",
      "10/10 - 0s - loss: 0.6799 - accuracy: 0.6522 - val_loss: 0.6820 - val_accuracy: 0.5862\n",
      "Epoch 3/200\n",
      "10/10 - 0s - loss: 0.6691 - accuracy: 0.6696 - val_loss: 0.6806 - val_accuracy: 0.5862\n",
      "Epoch 4/200\n",
      "10/10 - 0s - loss: 0.6620 - accuracy: 0.6696 - val_loss: 0.6809 - val_accuracy: 0.5862\n",
      "Epoch 5/200\n",
      "10/10 - 0s - loss: 0.6554 - accuracy: 0.6674 - val_loss: 0.6821 - val_accuracy: 0.5862\n",
      "Epoch 6/200\n",
      "10/10 - 0s - loss: 0.6523 - accuracy: 0.6674 - val_loss: 0.6832 - val_accuracy: 0.5862\n",
      "Epoch 7/200\n",
      "10/10 - 0s - loss: 0.6493 - accuracy: 0.6674 - val_loss: 0.6832 - val_accuracy: 0.5862\n",
      "Epoch 8/200\n",
      "10/10 - 0s - loss: 0.6479 - accuracy: 0.6674 - val_loss: 0.6842 - val_accuracy: 0.5862\n",
      "Epoch 9/200\n",
      "10/10 - 0s - loss: 0.6456 - accuracy: 0.6674 - val_loss: 0.6840 - val_accuracy: 0.5862\n",
      "Epoch 10/200\n",
      "10/10 - 0s - loss: 0.6440 - accuracy: 0.6674 - val_loss: 0.6840 - val_accuracy: 0.5862\n",
      "Epoch 11/200\n",
      "10/10 - 0s - loss: 0.6428 - accuracy: 0.6674 - val_loss: 0.6862 - val_accuracy: 0.5862\n",
      "Epoch 12/200\n",
      "10/10 - 0s - loss: 0.6410 - accuracy: 0.6674 - val_loss: 0.6870 - val_accuracy: 0.5862\n",
      "Epoch 13/200\n",
      "10/10 - 0s - loss: 0.6395 - accuracy: 0.6674 - val_loss: 0.6871 - val_accuracy: 0.5862\n",
      "Epoch 14/200\n",
      "10/10 - 0s - loss: 0.6385 - accuracy: 0.6674 - val_loss: 0.6861 - val_accuracy: 0.5862\n",
      "Epoch 15/200\n",
      "10/10 - 0s - loss: 0.6374 - accuracy: 0.6674 - val_loss: 0.6870 - val_accuracy: 0.5862\n",
      "Epoch 16/200\n",
      "10/10 - 0s - loss: 0.6359 - accuracy: 0.6674 - val_loss: 0.6847 - val_accuracy: 0.5862\n",
      "Epoch 17/200\n",
      "10/10 - 0s - loss: 0.6347 - accuracy: 0.6674 - val_loss: 0.6820 - val_accuracy: 0.5862\n",
      "Epoch 18/200\n",
      "10/10 - 0s - loss: 0.6335 - accuracy: 0.6674 - val_loss: 0.6781 - val_accuracy: 0.5862\n",
      "Epoch 19/200\n",
      "10/10 - 0s - loss: 0.6324 - accuracy: 0.6674 - val_loss: 0.6769 - val_accuracy: 0.5862\n",
      "Epoch 20/200\n",
      "10/10 - 0s - loss: 0.6315 - accuracy: 0.6674 - val_loss: 0.6777 - val_accuracy: 0.5862\n",
      "Epoch 21/200\n",
      "10/10 - 0s - loss: 0.6300 - accuracy: 0.6674 - val_loss: 0.6764 - val_accuracy: 0.5862\n",
      "Epoch 22/200\n",
      "10/10 - 0s - loss: 0.6291 - accuracy: 0.6674 - val_loss: 0.6771 - val_accuracy: 0.5862\n",
      "Epoch 23/200\n",
      "10/10 - 0s - loss: 0.6275 - accuracy: 0.6674 - val_loss: 0.6747 - val_accuracy: 0.5862\n",
      "Epoch 24/200\n",
      "10/10 - 0s - loss: 0.6261 - accuracy: 0.6674 - val_loss: 0.6745 - val_accuracy: 0.5862\n",
      "Epoch 25/200\n",
      "10/10 - 0s - loss: 0.6251 - accuracy: 0.6674 - val_loss: 0.6755 - val_accuracy: 0.5862\n",
      "Epoch 26/200\n",
      "10/10 - 0s - loss: 0.6236 - accuracy: 0.6674 - val_loss: 0.6742 - val_accuracy: 0.5862\n",
      "Epoch 27/200\n",
      "10/10 - 0s - loss: 0.6226 - accuracy: 0.6674 - val_loss: 0.6712 - val_accuracy: 0.5862\n",
      "Epoch 28/200\n",
      "10/10 - 0s - loss: 0.6208 - accuracy: 0.6674 - val_loss: 0.6704 - val_accuracy: 0.5862\n",
      "Epoch 29/200\n",
      "10/10 - 0s - loss: 0.6195 - accuracy: 0.6674 - val_loss: 0.6703 - val_accuracy: 0.5862\n",
      "Epoch 30/200\n",
      "10/10 - 0s - loss: 0.6181 - accuracy: 0.6674 - val_loss: 0.6681 - val_accuracy: 0.5862\n",
      "Epoch 31/200\n",
      "10/10 - 0s - loss: 0.6166 - accuracy: 0.6674 - val_loss: 0.6652 - val_accuracy: 0.5862\n",
      "Epoch 32/200\n",
      "10/10 - 0s - loss: 0.6152 - accuracy: 0.6674 - val_loss: 0.6600 - val_accuracy: 0.5862\n",
      "Epoch 33/200\n",
      "10/10 - 0s - loss: 0.6141 - accuracy: 0.6674 - val_loss: 0.6585 - val_accuracy: 0.5862\n",
      "Epoch 34/200\n",
      "10/10 - 0s - loss: 0.6124 - accuracy: 0.6674 - val_loss: 0.6555 - val_accuracy: 0.5862\n",
      "Epoch 35/200\n",
      "10/10 - 0s - loss: 0.6112 - accuracy: 0.6674 - val_loss: 0.6541 - val_accuracy: 0.5862\n",
      "Epoch 36/200\n",
      "10/10 - 0s - loss: 0.6093 - accuracy: 0.6674 - val_loss: 0.6540 - val_accuracy: 0.5862\n",
      "Epoch 37/200\n",
      "10/10 - 0s - loss: 0.6077 - accuracy: 0.6674 - val_loss: 0.6538 - val_accuracy: 0.5862\n",
      "Epoch 38/200\n",
      "10/10 - 0s - loss: 0.6066 - accuracy: 0.6674 - val_loss: 0.6537 - val_accuracy: 0.5862\n",
      "Epoch 39/200\n",
      "10/10 - 0s - loss: 0.6049 - accuracy: 0.6696 - val_loss: 0.6491 - val_accuracy: 0.5862\n",
      "Epoch 40/200\n",
      "10/10 - 0s - loss: 0.6034 - accuracy: 0.6696 - val_loss: 0.6498 - val_accuracy: 0.5862\n",
      "Epoch 41/200\n",
      "10/10 - 0s - loss: 0.6018 - accuracy: 0.6696 - val_loss: 0.6471 - val_accuracy: 0.5862\n",
      "Epoch 42/200\n",
      "10/10 - 0s - loss: 0.6001 - accuracy: 0.6696 - val_loss: 0.6440 - val_accuracy: 0.5862\n",
      "Epoch 43/200\n",
      "10/10 - 0s - loss: 0.5984 - accuracy: 0.6739 - val_loss: 0.6423 - val_accuracy: 0.5862\n",
      "Epoch 44/200\n",
      "10/10 - 0s - loss: 0.5967 - accuracy: 0.6739 - val_loss: 0.6411 - val_accuracy: 0.5862\n",
      "Epoch 45/200\n",
      "10/10 - 0s - loss: 0.5950 - accuracy: 0.6739 - val_loss: 0.6403 - val_accuracy: 0.5862\n",
      "Epoch 46/200\n",
      "10/10 - 0s - loss: 0.5935 - accuracy: 0.6739 - val_loss: 0.6385 - val_accuracy: 0.5862\n",
      "Epoch 47/200\n",
      "10/10 - 0s - loss: 0.5920 - accuracy: 0.6739 - val_loss: 0.6375 - val_accuracy: 0.5862\n",
      "Epoch 48/200\n",
      "10/10 - 0s - loss: 0.5903 - accuracy: 0.6761 - val_loss: 0.6354 - val_accuracy: 0.5862\n",
      "Epoch 49/200\n",
      "10/10 - 0s - loss: 0.5885 - accuracy: 0.6761 - val_loss: 0.6331 - val_accuracy: 0.5862\n",
      "Epoch 50/200\n",
      "10/10 - 0s - loss: 0.5864 - accuracy: 0.6761 - val_loss: 0.6282 - val_accuracy: 0.5862\n",
      "Epoch 51/200\n",
      "10/10 - 0s - loss: 0.5855 - accuracy: 0.6826 - val_loss: 0.6203 - val_accuracy: 0.6466\n",
      "Epoch 52/200\n",
      "10/10 - 0s - loss: 0.5827 - accuracy: 0.6957 - val_loss: 0.6209 - val_accuracy: 0.6379\n",
      "Epoch 53/200\n",
      "10/10 - 0s - loss: 0.5803 - accuracy: 0.6935 - val_loss: 0.6202 - val_accuracy: 0.6293\n",
      "Epoch 54/200\n",
      "10/10 - 0s - loss: 0.5787 - accuracy: 0.7000 - val_loss: 0.6155 - val_accuracy: 0.6207\n",
      "Epoch 55/200\n",
      "10/10 - 0s - loss: 0.5770 - accuracy: 0.6935 - val_loss: 0.6118 - val_accuracy: 0.6379\n",
      "Epoch 56/200\n",
      "10/10 - 0s - loss: 0.5749 - accuracy: 0.6978 - val_loss: 0.6116 - val_accuracy: 0.6379\n",
      "Epoch 57/200\n",
      "10/10 - 0s - loss: 0.5727 - accuracy: 0.6978 - val_loss: 0.6091 - val_accuracy: 0.6466\n",
      "Epoch 58/200\n",
      "10/10 - 0s - loss: 0.5708 - accuracy: 0.6891 - val_loss: 0.6032 - val_accuracy: 0.6810\n",
      "Epoch 59/200\n",
      "10/10 - 0s - loss: 0.5692 - accuracy: 0.6913 - val_loss: 0.5996 - val_accuracy: 0.6810\n",
      "Epoch 60/200\n",
      "10/10 - 0s - loss: 0.5672 - accuracy: 0.6913 - val_loss: 0.5992 - val_accuracy: 0.6810\n",
      "Epoch 61/200\n",
      "10/10 - 0s - loss: 0.5650 - accuracy: 0.7022 - val_loss: 0.5934 - val_accuracy: 0.6897\n",
      "Epoch 62/200\n",
      "10/10 - 0s - loss: 0.5638 - accuracy: 0.7109 - val_loss: 0.5921 - val_accuracy: 0.6810\n",
      "Epoch 63/200\n",
      "10/10 - 0s - loss: 0.5615 - accuracy: 0.7087 - val_loss: 0.5909 - val_accuracy: 0.6810\n",
      "Epoch 64/200\n",
      "10/10 - 0s - loss: 0.5595 - accuracy: 0.7065 - val_loss: 0.5901 - val_accuracy: 0.6810\n",
      "Epoch 65/200\n",
      "10/10 - 0s - loss: 0.5589 - accuracy: 0.7022 - val_loss: 0.5960 - val_accuracy: 0.6552\n",
      "Epoch 66/200\n",
      "10/10 - 0s - loss: 0.5563 - accuracy: 0.7043 - val_loss: 0.5879 - val_accuracy: 0.6724\n",
      "Epoch 67/200\n",
      "10/10 - 0s - loss: 0.5539 - accuracy: 0.7152 - val_loss: 0.5860 - val_accuracy: 0.6724\n",
      "Epoch 68/200\n",
      "10/10 - 0s - loss: 0.5526 - accuracy: 0.7152 - val_loss: 0.5866 - val_accuracy: 0.6724\n",
      "Epoch 69/200\n",
      "10/10 - 0s - loss: 0.5507 - accuracy: 0.7130 - val_loss: 0.5849 - val_accuracy: 0.6810\n",
      "Epoch 70/200\n",
      "10/10 - 0s - loss: 0.5491 - accuracy: 0.7152 - val_loss: 0.5843 - val_accuracy: 0.6724\n",
      "Epoch 71/200\n",
      "10/10 - 0s - loss: 0.5477 - accuracy: 0.7196 - val_loss: 0.5838 - val_accuracy: 0.6638\n",
      "Epoch 72/200\n",
      "10/10 - 0s - loss: 0.5476 - accuracy: 0.7217 - val_loss: 0.5877 - val_accuracy: 0.6552\n",
      "Epoch 73/200\n",
      "10/10 - 0s - loss: 0.5445 - accuracy: 0.7196 - val_loss: 0.5789 - val_accuracy: 0.6724\n",
      "Epoch 74/200\n",
      "10/10 - 0s - loss: 0.5432 - accuracy: 0.7370 - val_loss: 0.5661 - val_accuracy: 0.6724\n",
      "Epoch 75/200\n",
      "10/10 - 0s - loss: 0.5436 - accuracy: 0.7326 - val_loss: 0.5672 - val_accuracy: 0.6724\n",
      "Epoch 76/200\n",
      "10/10 - 0s - loss: 0.5391 - accuracy: 0.7239 - val_loss: 0.5766 - val_accuracy: 0.6638\n",
      "Epoch 77/200\n",
      "10/10 - 0s - loss: 0.5399 - accuracy: 0.7261 - val_loss: 0.5797 - val_accuracy: 0.6638\n",
      "Epoch 78/200\n",
      "10/10 - 0s - loss: 0.5389 - accuracy: 0.7326 - val_loss: 0.5626 - val_accuracy: 0.6724\n",
      "Epoch 79/200\n",
      "10/10 - 0s - loss: 0.5365 - accuracy: 0.7370 - val_loss: 0.5639 - val_accuracy: 0.6810\n",
      "Epoch 80/200\n",
      "10/10 - 0s - loss: 0.5342 - accuracy: 0.7217 - val_loss: 0.5699 - val_accuracy: 0.6724\n",
      "Epoch 81/200\n",
      "10/10 - 0s - loss: 0.5326 - accuracy: 0.7239 - val_loss: 0.5659 - val_accuracy: 0.6724\n",
      "Epoch 82/200\n",
      "10/10 - 0s - loss: 0.5320 - accuracy: 0.7348 - val_loss: 0.5595 - val_accuracy: 0.6810\n",
      "Epoch 83/200\n",
      "10/10 - 0s - loss: 0.5299 - accuracy: 0.7391 - val_loss: 0.5626 - val_accuracy: 0.6724\n",
      "Epoch 84/200\n",
      "10/10 - 0s - loss: 0.5285 - accuracy: 0.7370 - val_loss: 0.5621 - val_accuracy: 0.6724\n",
      "Epoch 85/200\n",
      "10/10 - 0s - loss: 0.5268 - accuracy: 0.7370 - val_loss: 0.5574 - val_accuracy: 0.6897\n",
      "Epoch 86/200\n",
      "10/10 - 0s - loss: 0.5254 - accuracy: 0.7413 - val_loss: 0.5581 - val_accuracy: 0.6897\n",
      "Epoch 87/200\n",
      "10/10 - 0s - loss: 0.5237 - accuracy: 0.7283 - val_loss: 0.5615 - val_accuracy: 0.6897\n",
      "Epoch 88/200\n",
      "10/10 - 0s - loss: 0.5227 - accuracy: 0.7326 - val_loss: 0.5575 - val_accuracy: 0.6810\n",
      "Epoch 89/200\n",
      "10/10 - 0s - loss: 0.5202 - accuracy: 0.7522 - val_loss: 0.5506 - val_accuracy: 0.6897\n",
      "Epoch 90/200\n",
      "10/10 - 0s - loss: 0.5211 - accuracy: 0.7478 - val_loss: 0.5497 - val_accuracy: 0.6897\n",
      "Epoch 91/200\n",
      "10/10 - 0s - loss: 0.5193 - accuracy: 0.7478 - val_loss: 0.5547 - val_accuracy: 0.6897\n",
      "Epoch 92/200\n",
      "10/10 - 0s - loss: 0.5168 - accuracy: 0.7565 - val_loss: 0.5521 - val_accuracy: 0.6810\n",
      "Epoch 93/200\n",
      "10/10 - 0s - loss: 0.5162 - accuracy: 0.7478 - val_loss: 0.5493 - val_accuracy: 0.6810\n",
      "Epoch 94/200\n",
      "10/10 - 0s - loss: 0.5154 - accuracy: 0.7587 - val_loss: 0.5530 - val_accuracy: 0.6810\n",
      "Epoch 95/200\n",
      "10/10 - 0s - loss: 0.5132 - accuracy: 0.7565 - val_loss: 0.5485 - val_accuracy: 0.6810\n",
      "Epoch 96/200\n",
      "10/10 - 0s - loss: 0.5122 - accuracy: 0.7630 - val_loss: 0.5490 - val_accuracy: 0.6724\n",
      "Epoch 97/200\n",
      "10/10 - 0s - loss: 0.5108 - accuracy: 0.7630 - val_loss: 0.5479 - val_accuracy: 0.6724\n",
      "Epoch 98/200\n",
      "10/10 - 0s - loss: 0.5095 - accuracy: 0.7674 - val_loss: 0.5468 - val_accuracy: 0.6724\n",
      "Epoch 99/200\n",
      "10/10 - 0s - loss: 0.5087 - accuracy: 0.7543 - val_loss: 0.5440 - val_accuracy: 0.6724\n",
      "Epoch 100/200\n",
      "10/10 - 0s - loss: 0.5072 - accuracy: 0.7522 - val_loss: 0.5438 - val_accuracy: 0.6638\n",
      "Epoch 101/200\n",
      "10/10 - 0s - loss: 0.5071 - accuracy: 0.7652 - val_loss: 0.5528 - val_accuracy: 0.6724\n",
      "Epoch 102/200\n",
      "10/10 - 0s - loss: 0.5057 - accuracy: 0.7609 - val_loss: 0.5423 - val_accuracy: 0.6810\n",
      "Epoch 103/200\n",
      "10/10 - 0s - loss: 0.5036 - accuracy: 0.7630 - val_loss: 0.5408 - val_accuracy: 0.6810\n",
      "Epoch 104/200\n",
      "10/10 - 0s - loss: 0.5029 - accuracy: 0.7674 - val_loss: 0.5374 - val_accuracy: 0.6897\n",
      "Epoch 105/200\n",
      "10/10 - 0s - loss: 0.5021 - accuracy: 0.7696 - val_loss: 0.5408 - val_accuracy: 0.6810\n",
      "Epoch 106/200\n",
      "10/10 - 0s - loss: 0.5001 - accuracy: 0.7696 - val_loss: 0.5415 - val_accuracy: 0.6724\n",
      "Epoch 107/200\n",
      "10/10 - 0s - loss: 0.4996 - accuracy: 0.7652 - val_loss: 0.5474 - val_accuracy: 0.6810\n",
      "Epoch 108/200\n",
      "10/10 - 0s - loss: 0.5002 - accuracy: 0.7652 - val_loss: 0.5465 - val_accuracy: 0.6810\n",
      "Epoch 109/200\n",
      "10/10 - 0s - loss: 0.5001 - accuracy: 0.7587 - val_loss: 0.5301 - val_accuracy: 0.7069\n",
      "Epoch 110/200\n",
      "10/10 - 0s - loss: 0.4983 - accuracy: 0.7696 - val_loss: 0.5370 - val_accuracy: 0.6810\n",
      "Epoch 111/200\n",
      "10/10 - 0s - loss: 0.4978 - accuracy: 0.7674 - val_loss: 0.5309 - val_accuracy: 0.6810\n",
      "Epoch 112/200\n",
      "10/10 - 0s - loss: 0.4932 - accuracy: 0.7761 - val_loss: 0.5431 - val_accuracy: 0.6724\n",
      "Epoch 113/200\n",
      "10/10 - 0s - loss: 0.4933 - accuracy: 0.7848 - val_loss: 0.5452 - val_accuracy: 0.6724\n",
      "Epoch 114/200\n",
      "10/10 - 0s - loss: 0.4918 - accuracy: 0.7783 - val_loss: 0.5363 - val_accuracy: 0.6810\n",
      "Epoch 115/200\n",
      "10/10 - 0s - loss: 0.4904 - accuracy: 0.7739 - val_loss: 0.5364 - val_accuracy: 0.6810\n",
      "Epoch 116/200\n",
      "10/10 - 0s - loss: 0.4899 - accuracy: 0.7739 - val_loss: 0.5319 - val_accuracy: 0.6897\n",
      "Epoch 117/200\n",
      "10/10 - 0s - loss: 0.4888 - accuracy: 0.7761 - val_loss: 0.5363 - val_accuracy: 0.6810\n",
      "Epoch 118/200\n",
      "10/10 - 0s - loss: 0.4876 - accuracy: 0.7804 - val_loss: 0.5375 - val_accuracy: 0.6897\n",
      "Epoch 119/200\n",
      "10/10 - 0s - loss: 0.4882 - accuracy: 0.7783 - val_loss: 0.5300 - val_accuracy: 0.6897\n",
      "Epoch 120/200\n",
      "10/10 - 0s - loss: 0.4863 - accuracy: 0.7761 - val_loss: 0.5325 - val_accuracy: 0.6897\n",
      "Epoch 121/200\n",
      "10/10 - 0s - loss: 0.4847 - accuracy: 0.7761 - val_loss: 0.5312 - val_accuracy: 0.6897\n",
      "Epoch 122/200\n",
      "10/10 - 0s - loss: 0.4835 - accuracy: 0.7783 - val_loss: 0.5328 - val_accuracy: 0.6897\n",
      "Epoch 123/200\n",
      "10/10 - 0s - loss: 0.4838 - accuracy: 0.7826 - val_loss: 0.5357 - val_accuracy: 0.6638\n",
      "Epoch 124/200\n",
      "10/10 - 0s - loss: 0.4815 - accuracy: 0.7826 - val_loss: 0.5296 - val_accuracy: 0.6724\n",
      "Epoch 125/200\n",
      "10/10 - 0s - loss: 0.4822 - accuracy: 0.7717 - val_loss: 0.5271 - val_accuracy: 0.6810\n",
      "Epoch 126/200\n",
      "10/10 - 0s - loss: 0.4801 - accuracy: 0.7783 - val_loss: 0.5354 - val_accuracy: 0.6810\n",
      "Epoch 127/200\n",
      "10/10 - 0s - loss: 0.4791 - accuracy: 0.7848 - val_loss: 0.5346 - val_accuracy: 0.6810\n",
      "Epoch 128/200\n",
      "10/10 - 0s - loss: 0.4791 - accuracy: 0.7783 - val_loss: 0.5274 - val_accuracy: 0.6897\n",
      "Epoch 129/200\n",
      "10/10 - 0s - loss: 0.4803 - accuracy: 0.7717 - val_loss: 0.5259 - val_accuracy: 0.6897\n",
      "Epoch 130/200\n",
      "10/10 - 0s - loss: 0.4772 - accuracy: 0.7826 - val_loss: 0.5368 - val_accuracy: 0.6638\n",
      "Epoch 131/200\n",
      "10/10 - 0s - loss: 0.4764 - accuracy: 0.7957 - val_loss: 0.5386 - val_accuracy: 0.6552\n",
      "Epoch 132/200\n",
      "10/10 - 0s - loss: 0.4761 - accuracy: 0.7957 - val_loss: 0.5398 - val_accuracy: 0.6552\n",
      "Epoch 133/200\n",
      "10/10 - 0s - loss: 0.4751 - accuracy: 0.7978 - val_loss: 0.5324 - val_accuracy: 0.6552\n",
      "Epoch 134/200\n",
      "10/10 - 0s - loss: 0.4735 - accuracy: 0.7891 - val_loss: 0.5315 - val_accuracy: 0.6552\n",
      "Epoch 135/200\n",
      "10/10 - 0s - loss: 0.4729 - accuracy: 0.7913 - val_loss: 0.5373 - val_accuracy: 0.6638\n",
      "Epoch 136/200\n",
      "10/10 - 0s - loss: 0.4724 - accuracy: 0.7957 - val_loss: 0.5308 - val_accuracy: 0.6638\n",
      "Epoch 137/200\n",
      "10/10 - 0s - loss: 0.4717 - accuracy: 0.7891 - val_loss: 0.5280 - val_accuracy: 0.6810\n",
      "Epoch 138/200\n",
      "10/10 - 0s - loss: 0.4717 - accuracy: 0.7913 - val_loss: 0.5254 - val_accuracy: 0.6897\n",
      "Epoch 139/200\n",
      "10/10 - 0s - loss: 0.4710 - accuracy: 0.7913 - val_loss: 0.5287 - val_accuracy: 0.6810\n",
      "Epoch 140/200\n",
      "10/10 - 0s - loss: 0.4700 - accuracy: 0.7978 - val_loss: 0.5332 - val_accuracy: 0.6552\n",
      "Epoch 141/200\n",
      "10/10 - 0s - loss: 0.4686 - accuracy: 0.8000 - val_loss: 0.5308 - val_accuracy: 0.6466\n",
      "Epoch 142/200\n",
      "10/10 - 0s - loss: 0.4681 - accuracy: 0.7957 - val_loss: 0.5306 - val_accuracy: 0.6552\n",
      "Epoch 143/200\n",
      "10/10 - 0s - loss: 0.4675 - accuracy: 0.8022 - val_loss: 0.5351 - val_accuracy: 0.6552\n",
      "Epoch 144/200\n",
      "10/10 - 0s - loss: 0.4688 - accuracy: 0.7957 - val_loss: 0.5267 - val_accuracy: 0.6724\n",
      "Epoch 145/200\n",
      "10/10 - 0s - loss: 0.4660 - accuracy: 0.8043 - val_loss: 0.5342 - val_accuracy: 0.6638\n",
      "Epoch 146/200\n",
      "10/10 - 0s - loss: 0.4653 - accuracy: 0.8022 - val_loss: 0.5273 - val_accuracy: 0.6724\n",
      "Epoch 147/200\n",
      "10/10 - 0s - loss: 0.4643 - accuracy: 0.7935 - val_loss: 0.5256 - val_accuracy: 0.6810\n",
      "Epoch 148/200\n",
      "10/10 - 0s - loss: 0.4660 - accuracy: 0.7978 - val_loss: 0.5227 - val_accuracy: 0.7155\n",
      "Epoch 149/200\n",
      "10/10 - 0s - loss: 0.4640 - accuracy: 0.7913 - val_loss: 0.5311 - val_accuracy: 0.6638\n",
      "Epoch 150/200\n",
      "10/10 - 0s - loss: 0.4625 - accuracy: 0.7978 - val_loss: 0.5310 - val_accuracy: 0.6638\n",
      "Epoch 151/200\n",
      "10/10 - 0s - loss: 0.4628 - accuracy: 0.8022 - val_loss: 0.5300 - val_accuracy: 0.6638\n",
      "Epoch 152/200\n",
      "10/10 - 0s - loss: 0.4612 - accuracy: 0.7978 - val_loss: 0.5280 - val_accuracy: 0.6810\n",
      "Epoch 153/200\n",
      "10/10 - 0s - loss: 0.4627 - accuracy: 0.7978 - val_loss: 0.5223 - val_accuracy: 0.7155\n",
      "Epoch 154/200\n",
      "10/10 - 0s - loss: 0.4604 - accuracy: 0.7913 - val_loss: 0.5277 - val_accuracy: 0.6810\n",
      "Epoch 155/200\n",
      "10/10 - 0s - loss: 0.4593 - accuracy: 0.7935 - val_loss: 0.5279 - val_accuracy: 0.6897\n",
      "Epoch 156/200\n",
      "10/10 - 0s - loss: 0.4586 - accuracy: 0.7957 - val_loss: 0.5247 - val_accuracy: 0.6897\n",
      "Epoch 157/200\n",
      "10/10 - 0s - loss: 0.4594 - accuracy: 0.7978 - val_loss: 0.5225 - val_accuracy: 0.7069\n",
      "Epoch 158/200\n",
      "10/10 - 0s - loss: 0.4588 - accuracy: 0.7978 - val_loss: 0.5269 - val_accuracy: 0.6810\n",
      "Epoch 159/200\n",
      "10/10 - 0s - loss: 0.4559 - accuracy: 0.8022 - val_loss: 0.5366 - val_accuracy: 0.6638\n",
      "Epoch 160/200\n",
      "10/10 - 0s - loss: 0.4582 - accuracy: 0.8065 - val_loss: 0.5387 - val_accuracy: 0.6810\n",
      "Epoch 161/200\n",
      "10/10 - 0s - loss: 0.4575 - accuracy: 0.8065 - val_loss: 0.5371 - val_accuracy: 0.6724\n",
      "Epoch 162/200\n",
      "10/10 - 0s - loss: 0.4564 - accuracy: 0.8022 - val_loss: 0.5339 - val_accuracy: 0.6724\n",
      "Epoch 163/200\n",
      "10/10 - 0s - loss: 0.4553 - accuracy: 0.8043 - val_loss: 0.5260 - val_accuracy: 0.6810\n",
      "Epoch 164/200\n",
      "10/10 - 0s - loss: 0.4546 - accuracy: 0.8000 - val_loss: 0.5308 - val_accuracy: 0.6638\n",
      "Epoch 165/200\n",
      "10/10 - 0s - loss: 0.4545 - accuracy: 0.7978 - val_loss: 0.5315 - val_accuracy: 0.6724\n",
      "Epoch 166/200\n",
      "10/10 - 0s - loss: 0.4544 - accuracy: 0.7957 - val_loss: 0.5277 - val_accuracy: 0.6724\n",
      "Epoch 167/200\n",
      "10/10 - 0s - loss: 0.4531 - accuracy: 0.7978 - val_loss: 0.5327 - val_accuracy: 0.6638\n",
      "Epoch 168/200\n",
      "10/10 - 0s - loss: 0.4530 - accuracy: 0.7957 - val_loss: 0.5293 - val_accuracy: 0.6810\n",
      "Epoch 169/200\n",
      "10/10 - 0s - loss: 0.4524 - accuracy: 0.8000 - val_loss: 0.5302 - val_accuracy: 0.6810\n",
      "Epoch 170/200\n",
      "10/10 - 0s - loss: 0.4520 - accuracy: 0.7978 - val_loss: 0.5279 - val_accuracy: 0.6810\n",
      "Epoch 171/200\n",
      "10/10 - 0s - loss: 0.4527 - accuracy: 0.7978 - val_loss: 0.5249 - val_accuracy: 0.6983\n",
      "Epoch 172/200\n",
      "10/10 - 0s - loss: 0.4520 - accuracy: 0.8000 - val_loss: 0.5282 - val_accuracy: 0.6810\n",
      "Epoch 173/200\n",
      "10/10 - 0s - loss: 0.4510 - accuracy: 0.7978 - val_loss: 0.5334 - val_accuracy: 0.6810\n",
      "Epoch 174/200\n",
      "10/10 - 0s - loss: 0.4504 - accuracy: 0.8000 - val_loss: 0.5312 - val_accuracy: 0.6897\n",
      "Epoch 175/200\n",
      "10/10 - 0s - loss: 0.4504 - accuracy: 0.8043 - val_loss: 0.5359 - val_accuracy: 0.6897\n",
      "Epoch 176/200\n",
      "10/10 - 0s - loss: 0.4510 - accuracy: 0.7978 - val_loss: 0.5211 - val_accuracy: 0.7155\n",
      "Epoch 177/200\n",
      "10/10 - 0s - loss: 0.4508 - accuracy: 0.8022 - val_loss: 0.5239 - val_accuracy: 0.6983\n",
      "Epoch 178/200\n",
      "10/10 - 0s - loss: 0.4486 - accuracy: 0.7978 - val_loss: 0.5277 - val_accuracy: 0.6897\n",
      "Epoch 179/200\n",
      "10/10 - 0s - loss: 0.4478 - accuracy: 0.7957 - val_loss: 0.5293 - val_accuracy: 0.6724\n",
      "Epoch 180/200\n",
      "10/10 - 0s - loss: 0.4492 - accuracy: 0.7978 - val_loss: 0.5323 - val_accuracy: 0.6810\n",
      "Epoch 181/200\n",
      "10/10 - 0s - loss: 0.4474 - accuracy: 0.8022 - val_loss: 0.5243 - val_accuracy: 0.6983\n",
      "Epoch 182/200\n",
      "10/10 - 0s - loss: 0.4476 - accuracy: 0.8022 - val_loss: 0.5312 - val_accuracy: 0.6897\n",
      "Epoch 183/200\n",
      "10/10 - 0s - loss: 0.4474 - accuracy: 0.7957 - val_loss: 0.5293 - val_accuracy: 0.6983\n",
      "Epoch 184/200\n",
      "10/10 - 0s - loss: 0.4464 - accuracy: 0.7978 - val_loss: 0.5334 - val_accuracy: 0.6897\n",
      "Epoch 185/200\n",
      "10/10 - 0s - loss: 0.4466 - accuracy: 0.8022 - val_loss: 0.5340 - val_accuracy: 0.6897\n",
      "Epoch 186/200\n",
      "10/10 - 0s - loss: 0.4453 - accuracy: 0.8000 - val_loss: 0.5294 - val_accuracy: 0.6983\n",
      "Epoch 187/200\n",
      "10/10 - 0s - loss: 0.4458 - accuracy: 0.7957 - val_loss: 0.5256 - val_accuracy: 0.7155\n",
      "Epoch 188/200\n",
      "10/10 - 0s - loss: 0.4451 - accuracy: 0.7935 - val_loss: 0.5303 - val_accuracy: 0.6983\n",
      "Epoch 189/200\n",
      "10/10 - 0s - loss: 0.4451 - accuracy: 0.8022 - val_loss: 0.5356 - val_accuracy: 0.6897\n",
      "Epoch 190/200\n",
      "10/10 - 0s - loss: 0.4461 - accuracy: 0.8000 - val_loss: 0.5368 - val_accuracy: 0.6897\n",
      "Epoch 191/200\n",
      "10/10 - 0s - loss: 0.4436 - accuracy: 0.8000 - val_loss: 0.5286 - val_accuracy: 0.6983\n",
      "Epoch 192/200\n",
      "10/10 - 0s - loss: 0.4445 - accuracy: 0.7913 - val_loss: 0.5261 - val_accuracy: 0.7155\n",
      "Epoch 193/200\n",
      "10/10 - 0s - loss: 0.4435 - accuracy: 0.7978 - val_loss: 0.5368 - val_accuracy: 0.6897\n",
      "Epoch 194/200\n",
      "10/10 - 0s - loss: 0.4430 - accuracy: 0.8000 - val_loss: 0.5342 - val_accuracy: 0.6810\n",
      "Epoch 195/200\n",
      "10/10 - 0s - loss: 0.4424 - accuracy: 0.7978 - val_loss: 0.5268 - val_accuracy: 0.7069\n",
      "Epoch 196/200\n",
      "10/10 - 0s - loss: 0.4427 - accuracy: 0.7935 - val_loss: 0.5301 - val_accuracy: 0.6897\n",
      "Epoch 197/200\n",
      "10/10 - 0s - loss: 0.4423 - accuracy: 0.8043 - val_loss: 0.5439 - val_accuracy: 0.6983\n",
      "Epoch 198/200\n",
      "10/10 - 0s - loss: 0.4431 - accuracy: 0.8043 - val_loss: 0.5375 - val_accuracy: 0.6897\n",
      "Epoch 199/200\n",
      "10/10 - 0s - loss: 0.4416 - accuracy: 0.8000 - val_loss: 0.5316 - val_accuracy: 0.6897\n",
      "Epoch 200/200\n",
      "10/10 - 0s - loss: 0.4411 - accuracy: 0.7978 - val_loss: 0.5352 - val_accuracy: 0.7069\n"
     ]
    }
   ],
   "source": [
    "history4 = model4.fit(\r\n",
    "    X_train, y_train, validation_split=0.2,\r\n",
    "    epochs=200, batch_size=50, verbose=2\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4545 - accuracy: 0.7812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4545283317565918, 0.78125]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.evaluate(X_test,y_test)\r\n",
    "# 스케일링 하자!!! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_acc = history4.history['accuracy']\r\n",
    "y_vloss = history4.history['val_loss']\r\n",
    "x_len = np.arange(len(y_acc))\r\n",
    "\r\n",
    "#epoch 늘릴수록 accuracy는 계속 좋아지나, valiation_loss 값은 낮아지다가 다시 약간 증가하는 형태를 지닌다.\r\n",
    "# 따라서 epochs 가 크되, valiation loss 값이 최소일때 학습을 끊어야한다!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\r\n",
    "plt.plot(x_len, y_acc, 'bo-', markersize=2, label='accuracy')\r\n",
    "plt.plot(x_len, y_vloss, 'ro-', markersize=2, label='val_loss')\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8c1eae21719a0790335dcb83aad72b63b602cfe5cdb2bda0f60bc11d4f154e4b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}